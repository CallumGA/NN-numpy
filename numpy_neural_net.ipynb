{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Classification Neural Net - NUMPY\n",
    "\n",
    "In this notebook I will develop a simple classification neural network from scratch using pythons NUMPY, instead of relying on libaries like pytorch."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T18:05:04.591318Z",
     "start_time": "2025-08-08T18:05:04.588808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "id": "807f76eb6a7a6401",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First we will define the constants that will be used throughout the notebook.",
   "id": "1580e508617d8033"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T18:05:04.609458Z",
     "start_time": "2025-08-08T18:05:04.607374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bias = 0\n",
    "learning_rate = 0.1\n",
    "truth = 1 # the value we expect (the actual value that's labeled )"
   ],
   "id": "972f031b596341a7",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Next, lets create some sample data to work with.\n",
    "- features: is (n_samples, n_features)\n",
    "- labels: is (n_samples, 1)\n"
   ],
   "id": "f8964909ebe70b81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T18:05:04.620729Z",
     "start_time": "2025-08-08T18:05:04.617585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(42)\n",
    "n_samples = 8\n",
    "n_features = 3\n",
    "features_matrix = np.random.rand(n_samples, n_features)\n",
    "labels = np.array([[0], [1], [0], [1], [0], [1], [0], [1]])\n",
    "weights_matrix = np.random.randn(n_features, 4)\n",
    "print(f\"X shape: {features_matrix.shape}\")\n",
    "print(features_matrix)\n",
    "print(f\"y shape: {labels.shape}\")\n",
    "print(labels)"
   ],
   "id": "7f046f99ac7d0fc6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (8, 3)\n",
      "[[0.37454012 0.95071431 0.73199394]\n",
      " [0.59865848 0.15601864 0.15599452]\n",
      " [0.05808361 0.86617615 0.60111501]\n",
      " [0.70807258 0.02058449 0.96990985]\n",
      " [0.83244264 0.21233911 0.18182497]\n",
      " [0.18340451 0.30424224 0.52475643]\n",
      " [0.43194502 0.29122914 0.61185289]\n",
      " [0.13949386 0.29214465 0.36636184]]\n",
      "y shape: (8, 1)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Neural Network Forward Pass – 1 Hidden Layer (NumPy variable names)\n",
    "\n",
    "We will create functions for each part of the forward pass:\n",
    "1. **Hidden layer linear transformation** – multiply the feature matrix by the weight matrix, add bias, and produce the pre-activation values for the hidden layer.\n",
    "2. **Hidden layer activation (ReLU)** – introduce non-linearity so the network can learn complex patterns.\n",
    "3. **Output layer linear transformation** – take the hidden layer activations, multiply by the output layer weights, add bias, and produce the output logits.\n",
    "4. **Output layer activation (Sigmoid)** – squash the logits into the range (0, 1) to get probabilities.\n",
    "5. **Loss (MSE)** – measure how far the predicted values are from the target labels.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Hidden layer linear transformation\n",
    "$$\n",
    "Z1 = \\text{features\\_matrix} \\cdot \\text{weights\\_matrix} + \\text{bias}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- `features_matrix` = input data `(n_samples, n_features)`\n",
    "- `weights_matrix` = hidden layer weights `(n_features, n_hidden)`\n",
    "- `bias` = hidden layer bias `(1, n_hidden)`\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Hidden layer activation (ReLU)\n",
    "$$\n",
    "A1 = \\max(0, Z1)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- `A1` = hidden layer activation output `(n_samples, n_hidden)`\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Output layer linear transformation\n",
    "$$\n",
    "Z2 = A1 \\cdot W2 + b2\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- `W2` = output layer weights `(n_hidden, 1)`\n",
    "- `b2` = output layer bias `(1, 1)`\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Output layer activation (Sigmoid)\n",
    "$$\n",
    "y_{\\text{pred}} = \\frac{1}{1 + e^{-Z2}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- `y_pred` = predicted probabilities `(n_samples, 1)`\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. Mean Squared Error (MSE) Loss\n",
    "$$\n",
    "\\text{loss} = \\frac{1}{n_{\\text{samples}}} \\sum_{i=1}^{n_{\\text{samples}}} \\left( y_{\\text{pred}_i} - y_i \\right)^2\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- `y` = true labels `(n_samples, 1)`\n"
   ],
   "id": "488cce66cffe9684"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T18:05:04.640607Z",
     "start_time": "2025-08-08T18:05:04.638170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hidden_layer_output_transformation(features_matrix, weights_matrix, bias):\n",
    "    output_matrix = features_matrix @ weights_matrix + bias\n",
    "    return output_matrix\n",
    "\n",
    "def hidden_ReLU_activation():\n",
    "    print(\"hidden layer activation\")\n",
    "\n",
    "def output_layer_transformation():\n",
    "    print(\"output layer\")\n",
    "\n",
    "def output_sigmoid_activation():\n",
    "    print(\"output sigmoid activation\")\n",
    "\n",
    "def MSE_loss():\n",
    "    print(\"MSE_loss\")\n",
    "\n",
    "hidden_layer_output = hidden_layer_output_transformation(features_matrix, weights_matrix, bias)\n",
    "print(hidden_layer_output)"
   ],
   "id": "9be632b40e61654",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.40827206 -0.19262465 -1.50941963  1.17941254]\n",
      " [ 0.69879287 -0.16335953 -0.23301305 -0.50537645]\n",
      " [-0.74745409 -0.09237689 -1.35473578  1.35609836]\n",
      " [ 0.44401448 -0.44049936 -0.55947892  0.79545129]\n",
      " [ 0.99526368 -0.21742982 -0.29759288 -0.76945534]\n",
      " [-0.21200664 -0.16072923 -0.65354531  0.82499286]\n",
      " [ 0.10703705 -0.24369272 -0.67419033  0.6273231 ]\n",
      " [-0.17464059 -0.10595443 -0.54727919  0.58961859]]\n"
     ]
    }
   ],
   "execution_count": 49
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
